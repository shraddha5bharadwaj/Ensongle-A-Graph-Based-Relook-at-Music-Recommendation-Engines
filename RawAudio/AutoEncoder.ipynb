{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"bmVmAqNoDLch"},"outputs":[],"source":["# !pip install livelossplot"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HxFNWAonaydF"},"outputs":[],"source":["import tensorflow as tf\n","from tqdm import tqdm\n","import os\n","import math\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import librosa\n","import librosa.display\n","from livelossplot import PlotLossesKeras\n","# import torchaudio\n","import random\n","import pandas as pd\n","from IPython.display import clear_output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nnMY4S29vO1m"},"outputs":[],"source":["def plot_spectrogram(spec, title=None, ylabel='freq_bin', aspect='auto', xmax=None):\n","    fig, axs = plt.subplots(1, 1)\n","    axs.set_title(title or 'Spectrogram (db)')\n","    axs.set_ylabel(ylabel)\n","    axs.set_xlabel('frame')\n","    im = axs.imshow(librosa.power_to_db(spec), origin='lower', aspect=aspect)\n","    if xmax:\n","        axs.set_xlim((0, xmax))\n","        fig.colorbar(im, ax=axs)\n","        plt.show(block=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"code","id":"TEr1mvDHSxIr"},"outputs":[],"source":["encoder_input = tf.keras.Input(shape = (256,4096,1),name = \"mel\")\n","x = tf.keras.layers.Conv2D(\n","    filters= 512,\n","    activation = \"relu\",\n","    kernel_size = 3,\n","    strides = 2,\n","    padding = \"same\",\n","    name=f\"Encoder_Conv2d_{1}\"\n","    )(encoder_input)\n","x = tf.keras.layers.BatchNormalization(name=f\"Encoder_BatchNorm_{1}\")(x)\n","\n","x = tf.keras.layers.Conv2D(\n","    filters= 256,\n","    activation = \"relu\",\n","    kernel_size = 3,\n","    strides = 2,\n","    padding = \"same\",\n","    name=f\"Encoder_Conv2d_{2}\"\n","    )(x)\n","x = tf.keras.layers.BatchNormalization(name=f\"Encoder_BatchNorm_{2}\")(x)\n","\n","x = tf.keras.layers.Conv2D(\n","    filters= 128,\n","    activation = \"relu\",\n","    kernel_size = 3,\n","    strides = 2,\n","    padding = \"same\",\n","    name=f\"Encoder_Conv2d_{3}\"\n","    )(x)\n","x = tf.keras.layers.BatchNormalization(name=f\"Encoder_BatchNorm_{3}\")(x)\n","\n","x = tf.keras.layers.Conv2D(\n","    filters= 64,\n","    activation = \"relu\",\n","    kernel_size = 3,\n","    strides = 2,\n","    padding = \"same\",\n","    name=f\"Encoder_Conv2d_{4}\"\n","    )(x)\n","x = tf.keras.layers.BatchNormalization(name=f\"Encoder_BatchNorm_{4}\")(x)\n","\n","x = tf.keras.layers.Conv2D(\n","    filters= 32,\n","    activation = \"relu\",\n","    kernel_size = 3,\n","    strides = 2,\n","    padding = \"same\",\n","    name=f\"Encoder_Conv2d_{5}\"\n","    )(x)\n","x = tf.keras.layers.BatchNormalization(name=f\"Encoder_BatchNorm_{5}\")(x)\n","\n","x = tf.keras.layers.Flatten()(x)\n","encoder_output = tf.keras.layers.Dense(64,activation=\"relu\")(x)\n","decoder_input = tf.keras.layers.Dense(32768,activation=\"relu\")(encoder_output)\n","x = tf.keras.layers.Reshape((8,128,32))(decoder_input)\n","\n","# Decode block\n","x = tf.keras.layers.Conv2DTranspose(\n","filters= 64,\n","activation = \"relu\",\n","kernel_size = 3,\n","strides = 2,\n","padding = \"same\",\n","name=f\"Decoder_Conv2d_{1}\"\n",")(x)\n","x = tf.keras.layers.BatchNormalization(name=f\"Decoder_BatchNorm_{1}\")(x)\n","\n","x = tf.keras.layers.Conv2DTranspose(\n","filters= 128,\n","activation = \"relu\",\n","kernel_size = 3,\n","strides = 2,\n","padding = \"same\",\n","name=f\"Decoder_Conv2d_{2}\"\n",")(x)\n","x = tf.keras.layers.BatchNormalization(name=f\"Decoder_BatchNorm_{2}\")(x)\n","\n","x = tf.keras.layers.Conv2DTranspose(\n","filters= 256,\n","activation = \"relu\",\n","kernel_size = 3,\n","strides = 2,\n","padding = \"same\",\n","name=f\"Decoder_Conv2d_{3}\"\n",")(x)\n","x = tf.keras.layers.BatchNormalization(name=f\"Decoder_BatchNorm_{3}\")(x)\n","\n","x = tf.keras.layers.Conv2DTranspose(\n","filters= 512,\n","activation = \"relu\",\n","kernel_size = 3,\n","strides = 2,\n","padding = \"same\",\n","name=f\"Decoder_Conv2d_{4}\"\n",")(x)\n","x = tf.keras.layers.BatchNormalization(name=f\"Decoder_BatchNorm_{4}\")(x)\n","\n","final_output = tf.keras.layers.Conv2DTranspose(\n","filters= 1,\n","activation = \"linear\",\n","kernel_size = 3,\n","strides = 2,\n","padding = \"same\",\n","name=f\"Decoder_Conv2d_{5}\"\n",")(x)\n","\n","AutoEncoder = tf.keras.Model(encoder_input,final_output,name = \"AutoEncoder\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FNRA_h2nhbQp"},"outputs":[],"source":["# AutoEncoder.load_weights(\"final_checkpoints/cp-0009.ckpt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2n1nXrDZaYzW"},"outputs":[],"source":["class TrainGenerator(tf.keras.utils.Sequence):\n","    def __init__(self, batch_size: int = 32, validate_: bool = False, shuffle: bool = True):\n","        self.shuffle = shuffle\n","        self.batch_size = batch_size\n","        self.relative_path = \"Single_NPYs/\"\n","        self.song_npys = os.listdir(self.relative_path)\n","        self.validate_ = validate_\n","\n","        self.song_indices = np.asarray(list(range(len(self.song_npys))))\n","        self.len_dataset = len(self.song_npys)\n","        # if self.validate_== False:\n","        #     self.song_indices = self.song_indices[:int(0.8*self.len_dataset)]\n","        # else:\n","        #     self.song_indices = self.song_indices[int(0.8*self.len_dataset):]\n","        self.len_dataset = self.song_indices.shape[0]\n","        if self.shuffle:\n","            self.__shuffle()\n","\n","    def __shuffle(self):\n","        shuffler = np.random.permutation(self.len_dataset)\n","        self.song_indices = self.song_indices[shuffler]\n","\n","    def __len__(self):\n","        return math.ceil(self.len_dataset / self.batch_size)\n","\n","    def __getitem__(self, index):\n","        temp_indices = self.song_indices[index*self.batch_size:(index+1)*self.batch_size]\n","        data = np.zeros((temp_indices.shape[0],256,4096,1))\n","        for ind, value in enumerate(temp_indices):\n","            path = self.relative_path+self.song_npys[value]\n","            data[ind] = np.asarray(np.load(path, allow_pickle=True))\n","        return data, data\n","\n","    def on_epoch_end(self):\n","        if self.shuffle:\n","            self.__shuffle()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PyfMiOiXdphW"},"outputs":[],"source":["training_generator = TrainGenerator(batch_size=4)\n","# validation_generator = TrainGenerator(batch_size=4, validate_=True, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Htou9UAHdBu_"},"outputs":[],"source":["checkpoint_path = \"after_9_checkpoints/cp-{epoch:04d}.ckpt\"\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_path,\n","    save_weights_only=True,\n","    save_freq=len(training_generator)*1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PX6IWkTwaydO"},"outputs":[],"source":["phase1_hist=[]\n","AutoEncoder.compile(\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=0.005),\n","    loss=\"mse\",\n","    metrics=[\"mae\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"lr7FjDVnuko4"},"outputs":[],"source":["history = AutoEncoder.fit(training_generator, \n","            callbacks=[model_checkpoint_callback, PlotLossesKeras()],\n","            # validation_data=validation_generator, \n","            epochs=3)\n","phase1_hist.append(history)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GtCEUtdu8QSz"},"outputs":[],"source":["from tqdm import tqdm\n","lis_fail = []\n","folder = \"Single_NPYs/\"\n","cor = 0\n","fa = 0\n","for i in tqdm(os.listdir(folder), ncols = 100):\n","    try:\n","        ttt = np.load(folder + i, allow_pickle=True)\n","        cor += 1\n","    except:\n","        fa += 1\n","        lis_fail.append(i)\n","print(\"Correct =\", cor)\n","print(\"False =\", lis_fail)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gI6axC5lmaBh"},"outputs":[],"source":["def plot_spectrogram(spec, title=None, ylabel='freq_bin', aspect='auto', xmax=None):\n","    fig, axs = plt.subplots(1, 1)\n","    axs.set_title(title or 'Spectrogram (db)')\n","    axs.set_ylabel(ylabel)\n","    axs.set_xlabel('frame')\n","    im = axs.imshow(librosa.power_to_db(spec), origin='lower', aspect=aspect)\n","    if xmax:\n","        axs.set_xlim((0, xmax))\n","        fig.colorbar(im, ax=axs)\n","        plt.show(block=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sYDMVSyVq4Tp"},"outputs":[],"source":["hist_mae=[]\n","hist_mae_val=[]\n","hist_loss=[]\n","hist_loss_val=[]\n","for i in phase1_hist:\n","    hist_mae.extend(i.history['mae'])\n","    hist_mae_val.extend(i.history['val_mae'])\n","    hist_loss.extend(i.history['loss'])\n","    hist_loss_val.extend(i.history['val_loss'])\n","\n","# summarize history for mae\n","plt.plot(hist_mae)\n","plt.plot(hist_mae_val)\n","plt.title('mae'); plt.ylabel('mae'); plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper right')\n","plt.show()\n","\n","# summarize history for loss\n","plt.plot(hist_loss)\n","plt.plot(hist_loss_val)\n","plt.title('loss'); plt.ylabel('loss'); plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper right')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E0nlUJSAL00y"},"outputs":[],"source":["cols = [str(i) for i in range(0,64)]\n","\n","# track_features = pd.DataFrame(columns = ['song_id', *cols])\n","track_features = pd.read_csv('track_features.csv')\n","done_songs = set(track_features[\"song_id\"])\n","\n","def add_to_df():\n","    global track_features\n","    for i in encodings:\n","        if i not in done_songs:\n","            song = {}\n","            song['song_id'] = i\n","            for j in cols:\n","                song[str(j)] = encodings[i][int(j)]\n","            track_features = track_features.append(song, ignore_index = True)\n","            done_songs.add(i)\n","    track_features.to_csv('track_features.csv', index = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-FRU5kQf-RUu"},"outputs":[],"source":["len(done_songs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8XzmE5TzLSUl"},"outputs":[],"source":["track_features.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p6kYDoqF-O_w"},"outputs":[],"source":["numpy_files = os.listdir('Single_NPYs')\n","encodings = {}\n","intermediate_layer_model = tf.keras.Model(inputs=AutoEncoder.input,\n","                                       outputs=AutoEncoder.layers[12].output)\n","\n","batch_size = 1\n","count = 0\n","count_total = 0\n","inp_array = np.zeros((batch_size, 256,4096,1))\n","inp_names = ['name' for i in range(batch_size)]\n","for song in tqdm(sorted(numpy_files), ncols = 100):\n","    if song.split(\".\")[0] in done_songs:\n","        continue\n","    print(song)\n","    inp_array[count] = np.expand_dims(np.load(\"Single_NPYs/\"+song, allow_pickle = True), axis=0)\n","    inp_names[count] = song\n","    count = (count + 1) % batch_size\n","\n","    if count % batch_size == 0:\n","        out_array = intermediate_layer_model(inp_array).numpy()\n","\n","        for i in range(batch_size):\n","            encodings[inp_names[i].split(\".\")[0]] = out_array[i]\n","        inp_array = np.zeros((batch_size, 256,4096,1))\n","        inp_names = ['name' for i in range(batch_size)]\n","\n","    if count_total % (batch_size * 50) == 0:\n","        add_to_df()\n","        print(\"added \"+str(count_total)+\" songs to csv\")\n","        clear_output(wait=True)\n","    count_total += 1\n","add_to_df()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"AutoEncoder.ipynb","provenance":[]},"interpreter":{"hash":"5f7ff212da0a5c6715015bf25b42af0be30887e238caa227b88730d1a9a929a4"},"kernelspec":{"display_name":"Python 3.8.10 64-bit ('Capstone': venv)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}
